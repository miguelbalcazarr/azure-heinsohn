{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5772ba27-ef3e-44a0-a2ce-64579c5cd544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extracci√≥n de Datos a la Capa Bronze en Azure Databricks\n",
    "\n",
    "Este notebook implementa el proceso de extracci√≥n de datos desde las tablas operativas del sistema de gesti√≥n de internamientos cl√≠nicos hacia la capa Bronze del Data Lakehouse en Azure, utilizando Delta Lake con tablas gestionadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bbac2c4-47dd-49a7-bba0-c35fce7acfcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Consulta a las tablas del Origen de datos y traerla a Dataframe\n",
    "Definimos una funcion para conectarnos a SQL Server y cargar todo a un Dataframe Generico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be11ad0a-3b4c-4f86-ab7a-a6f0f30e4c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def leer_tablas_sql_azure(lista_tablas, lista_modos_carga, fecha_corte, url_conexion, usuario, password,\n",
    "                          esquemas=None, columna_incremental=\"fecalta\"):\n",
    "    \"\"\"\n",
    "    Lee m√∫ltiples tablas desde Azure SQL Database, usando carga full o incremental por tabla.\n",
    "\n",
    "    Par√°metros:\n",
    "    - lista_tablas: lista de nombres de tablas a leer.\n",
    "    - lista_modos_carga: lista del mismo tama√±o que lista_tablas con 'full' o 'incremental'.\n",
    "    - fecha_corte: fecha para filtro incremental.\n",
    "    - url_conexion: cadena JDBC a Azure SQL.\n",
    "    - usuario: nombre de usuario de conexi√≥n.\n",
    "    - password: contrase√±a.\n",
    "    - esquemas: dict opcional {tabla: esquema}, por defecto usa 'dbo'.\n",
    "    - columna_incremental: nombre de la columna de fecha para carga incremental.\n",
    "\n",
    "    Retorna:\n",
    "    - None. Crea variables globales con los DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(lista_tablas) != len(lista_modos_carga):\n",
    "        raise ValueError(\"Las listas 'lista_tablas' y 'lista_modos_carga' deben tener la misma longitud.\")\n",
    "\n",
    "    properties = {\n",
    "        \"user\": usuario,\n",
    "        \"password\": password,\n",
    "        \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "    }\n",
    "\n",
    "    for i, nombre_tabla in enumerate(lista_tablas):\n",
    "        modo_carga = lista_modos_carga[i].lower()\n",
    "        esquema = esquemas.get(nombre_tabla, \"dbo\") if esquemas else \"dbo\"\n",
    "        tabla_completa = f\"{esquema}.{nombre_tabla}\"\n",
    "        query = \"\"\n",
    "        base_query = f\"(SELECT * FROM {tabla_completa}) AS temp\"\n",
    "\n",
    "        try:\n",
    "            # Validar existencia de columna incremental\n",
    "            df_sample = spark.read.jdbc(url=url_conexion, table=base_query, properties=properties).limit(10)\n",
    "\n",
    "            if modo_carga == \"incremental\":\n",
    "                if columna_incremental in df_sample.columns:\n",
    "                    query = f\"(SELECT * FROM {tabla_completa} WHERE {columna_incremental} = '{fecha_corte}') AS temp\"\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è  Tabla '{tabla_completa}' sin columna '{columna_incremental}'. Se leer√° completa.\")\n",
    "                    query = base_query\n",
    "            else:\n",
    "                query = base_query\n",
    "\n",
    "            df = spark.read.jdbc(url=url_conexion, table=query, properties=properties)\n",
    "            globals()[nombre_tabla] = df\n",
    "\n",
    "            print(f\"‚úÖ DataFrame '{nombre_tabla}' ({modo_carga}) cargado desde '{tabla_completa}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al leer la tabla '{tabla_completa}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7d7a071-3f0c-438d-b922-6a9f17ea4183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Par√°metros de conexi√≥n\n",
    "url_conexion = dbutils.secrets.get(\"scope-dev\", \"secret-sql-ventas-url\")\n",
    "usuario = dbutils.secrets.get(\"scope-dev\", \"secret-sql-ventas-user\")\n",
    "password = dbutils.secrets.get(\"scope-dev\", \"secret-sql-ventas-password\")\n",
    "fecha_carga = \"2025-08-01\"\n",
    "#properties = {\"user\": \"admin01juls\", \"password\": \"287719Julius@12\", \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"}\n",
    "\n",
    "# Lista de tablas a leer\n",
    "lista_tablas = [\"subcategoria\", \"categoria\", \"producto\", \"ubigeo\",\"segmento\",\"mercado\", \"SECTORECONOMICO\", \"PEDIDO\",\n",
    "                \"cliente\", \"VENDEDOR\", \"MODALIDADENVIO\", \"MODALIDADVENTA\", \"MONEDA\",  \"mediopago\" , \"PRIORIDADPEDIDO\"]\n",
    "esquemas = {}\n",
    "modos = [\"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"full\", \"incremental\", \"full\",\"full\", \"full\", \"full\", \"full\", \"full\", \"full\"]\n",
    "\n",
    "# Llamar la funci√≥n para crear DataFrames individuales\n",
    "leer_tablas_sql_azure(lista_tablas, modos, fecha_carga, url_conexion, usuario, password, esquemas, columna_incremental=\"FECCARGA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d511822-faf8-4178-ba48-f1a99481e689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# BRONZE - limpieza y estandarizaci√≥n m√≠nima\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, lit, to_timestamp, year, month, dayofmonth\n",
    ")\n",
    "from pyspark.sql.types import (\n",
    "    DataType, DoubleType, FloatType, IntegerType, LongType, ShortType,\n",
    "    DecimalType, StringType, TimestampType\n",
    ")\n",
    "\n",
    "def _bronze_zero_for_type(dt: DataType):\n",
    "    if isinstance(dt, (DoubleType, FloatType, DecimalType)):\n",
    "        return lit(0.0)\n",
    "    if isinstance(dt, (IntegerType, LongType, ShortType)):\n",
    "        return lit(0)\n",
    "    if isinstance(dt, StringType):\n",
    "        return lit(\"\")\n",
    "    if isinstance(dt, TimestampType):\n",
    "        return lit(None).cast(\"timestamp\")\n",
    "    return lit(0)\n",
    "\n",
    "def limpiar_bronze(\n",
    "    df: DataFrame,\n",
    "    casts: Optional[Dict[str, str]] = None,\n",
    "    date_col: Optional[str] = None,\n",
    "    date_fmt: str = \"yyyy-MM-dd HH:mm:ss\",\n",
    "    extract_date_parts: bool = True,\n",
    "    fillna_map: Optional[Dict[str, object]] = None,\n",
    "    dedup_subset: Optional[List[str]] = None,\n",
    "    non_negative_cols: Optional[List[str]] = None,\n",
    "    drop_cols: Optional[List[str]] = None,\n",
    "    compute_metrics: bool = True,                 # NUEVO: evita counts si no los necesitas\n",
    "    output: str = \"both\"                          # NUEVO: \"df\" o \"both\"\n",
    ") -> Union[DataFrame, Tuple[DataFrame, Dict]]:\n",
    "    \"\"\"\n",
    "    Limpieza t√≠pica de Bronze:\n",
    "    - Casts de tipos.\n",
    "    - Parse/normalizaci√≥n de fecha y particiones (year/month/day).\n",
    "    - Relleno de nulos (incluye timestamps).\n",
    "    - Correcci√≥n de negativos en columnas num√©ricas.\n",
    "    - Drop de columnas innecesarias.\n",
    "    - Deduplicaci√≥n (subset o todas las columnas).\n",
    "\n",
    "    Retorna:\n",
    "      - si output=\"df\": DataFrame\n",
    "      - si output=\"both\": (DataFrame, dq_metrics)\n",
    "    \"\"\"\n",
    "    dq = {}\n",
    "\n",
    "    # M√©trica de entrada\n",
    "    if compute_metrics:\n",
    "        dq[\"rows_in\"] = df.count()\n",
    "\n",
    "    # 1) Casts\n",
    "    if casts:\n",
    "        for c, t in casts.items():\n",
    "            if c in df.columns:\n",
    "                if t.lower() == \"timestamp\" and not isinstance(df.schema[c].dataType, TimestampType):\n",
    "                    df = df.withColumn(c, to_timestamp(col(c), date_fmt))\n",
    "                else:\n",
    "                    df = df.withColumn(c, col(c).cast(t))\n",
    "\n",
    "    # 2) Fecha base y particiones\n",
    "    if date_col and date_col in df.columns:\n",
    "        if not isinstance(df.schema[date_col].dataType, TimestampType):\n",
    "            df = df.withColumn(date_col, to_timestamp(col(date_col), date_fmt))\n",
    "        if extract_date_parts:\n",
    "            df = (\n",
    "                df\n",
    "                .withColumn(\"year\",  year(col(date_col)).cast(\"string\"))\n",
    "                .withColumn(\"month\", month(col(date_col)).cast(\"string\"))\n",
    "                .withColumn(\"day\",   dayofmonth(col(date_col)).cast(\"string\"))\n",
    "            )\n",
    "\n",
    "    # 3) Fill de nulos (incl. timestamps)\n",
    "    if fillna_map:\n",
    "        ts_cols = [c for c, _ in fillna_map.items()\n",
    "                   if c in df.columns and isinstance(df.schema[c].dataType, TimestampType)]\n",
    "        # no-timestamps\n",
    "        plain_map = {c: v for c, v in fillna_map.items() if c in df.columns and c not in ts_cols}\n",
    "        if plain_map:\n",
    "            df = df.fillna(plain_map)\n",
    "        # timestamps\n",
    "        for c in ts_cols:\n",
    "            v = fillna_map[c]\n",
    "            if isinstance(v, str):\n",
    "                df = df.withColumn(c, when(col(c).isNull(), to_timestamp(lit(v), date_fmt)).otherwise(col(c)))\n",
    "            else:\n",
    "                df = df.withColumn(c, when(col(c).isNull(), lit(v).cast(\"timestamp\")).otherwise(col(c)))\n",
    "\n",
    "    # 4) No negativos\n",
    "    if non_negative_cols:\n",
    "        for c in non_negative_cols:\n",
    "            if c in df.columns:\n",
    "                zero = _bronze_zero_for_type(df.schema[c].dataType)\n",
    "                df = df.withColumn(c, when(col(c) < 0, zero).otherwise(col(c)))\n",
    "\n",
    "    # 5) Drop columns\n",
    "    if drop_cols:\n",
    "        keep = [c for c in df.columns if c not in set(drop_cols)]\n",
    "        df = df.select(*keep)\n",
    "\n",
    "    # 6) Deduplicaci√≥n\n",
    "    if compute_metrics:\n",
    "        before_dedup = df.count()\n",
    "    df = df.dropDuplicates(dedup_subset) if dedup_subset else df.dropDuplicates()\n",
    "    if compute_metrics:\n",
    "        after_dedup = df.count()\n",
    "        dq[\"rows_after_fill_cast\"] = before_dedup\n",
    "        dq[\"duplicates_removed\"] = before_dedup - after_dedup\n",
    "        dq[\"rows_out\"] = after_dedup\n",
    "\n",
    "    # --- Salida controlada ---\n",
    "    if output == \"df\":\n",
    "        return df\n",
    "    # default: \"both\"\n",
    "    return df, dq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4602173-454e-4296-aaf9-5f5843872526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Producto, dq = limpiar_bronze(\n",
    "    producto,\n",
    "    casts={\"IDPRODUCTO\":\"int\",\"CODMNDA\":\"int\",\"CODSUBCAT\":\"int\",\"MTOPRECUNIT\":\"double\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"IDPRODUCTO\":0,\"CODMNDA\":0,\"CODSUBCAT\":0,\"MTOPRECUNIT\":0.0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"IDPRODUCTO\",\"MTOPRECUNIT\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "612f056f-4d6e-4b74-b0eb-d5a7647b8d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Categoria, dq = limpiar_bronze(\n",
    "    categoria,\n",
    "    casts={\"CODCAT\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODCAT\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODCAT\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56b102b-f5f3-48a8-9bd9-9387a016b0bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Subcategoria, dq = limpiar_bronze(\n",
    "    subcategoria,\n",
    "    casts={\"CODSUBCAT\":\"int\",\"CODCAT\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODSUBCAT\":0,\"CODCAT\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODSUBCAT\",\"CODCAT\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f594c62-d215-4ae5-8eba-684a54090718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Segmento, dq = limpiar_bronze(\n",
    "    segmento,\n",
    "    casts={\"CODSGMNTO\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODSGMNTO\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODSGMNTO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd360c64-66d5-4b22-92ea-f84f33ad5d7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Mercado, dq = limpiar_bronze(\n",
    "    mercado,\n",
    "    casts={\"CODMRCADO\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODMRCADO\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODMRCADO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1cb06b9-4f37-41f3-bc7e-7b7bdcd49bd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Ubigeo, dq = limpiar_bronze(\n",
    "    ubigeo,\n",
    "    casts={\"CODUBIGEO\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODUBIGEO\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODUBIGEO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe4e2ca-8304-4a3f-9c15-015e9d55feb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Sectoreconomico, dq = limpiar_bronze(\n",
    "    SECTORECONOMICO,\n",
    "    casts={\"CODSECTECON\":\"int\",\"CODSGMNTO\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODSECTECON\":0, \"CODSGMNTO\":0,\"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODSECTECON\",\"CODSGMNTO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe35110-dd0d-4a97-b24e-f48fae0cf8be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Vendedor, dq = limpiar_bronze(\n",
    "    VENDEDOR,\n",
    "    casts={\"CODVEND\":\"int\",\"CODMNDA\":\"int\", \"MTOSUELDOBASE\":\"double\", \"PCTCOMIS\":\"double\", \"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODVEND\":0, \"CODMNDA\":0, \"MTOSUELDOBASE\":0, \"PCTCOMIS\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODVEND\",\"CODUBIGEO\", \"MTOSUELDOBASE\", \"PCTCOMIS\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c5bd14c-360d-4393-87da-0936e09a8f17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Moneda, dq = limpiar_bronze(\n",
    "    MONEDA,\n",
    "    casts={\"CODMNDA\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODMNDA\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODMNDA\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b3393ee-67ba-4213-a505-decf40476cfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Prioridadpedido, dq = limpiar_bronze(\n",
    "    PRIORIDADPEDIDO,\n",
    "    casts={\"CODPRIORPEDI\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODPRIORPEDI\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODPRIORPEDI\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fbad5aa-1812-4849-ba9a-49645801d476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Modalidadventa, dq = limpiar_bronze(\n",
    "    MODALIDADVENTA,\n",
    "    casts={\"CODMODVALVTA\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODMODVALVTA\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODMODVALVTA\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee17457-752f-413d-9e19-ce790a34cce4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_ModalidadEnvio, dq = limpiar_bronze(\n",
    "    MODALIDADENVIO,\n",
    "    casts={\"CODMODALENV\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODMODALENV\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODMODALENV\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b65b66ef-a38e-4e76-b2d5-ed8d0578e882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Mediopago, dq = limpiar_bronze(\n",
    "    mediopago,\n",
    "    casts={\"CODMEDIOPAGO\":\"int\",\"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"CODMEDIOPAGO\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"CODMEDIOPAGO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c88967c-211f-4851-aff2-aa75f559b10a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_Pedido, dq = limpiar_bronze(\n",
    "    PEDIDO,\n",
    "    casts={\"PEDIDO\":\"int\", \"CTDPEDID\":\"int\", \"CODMODVALVTA\":\"int\", \"CODMEDIOPAGO\":\"int\", \"CODVEND\":\"int\", \"CODMNDA\":\"int\", \"IDCLI\":\"int\", \"IDPRODUCTO\":\"int\", \n",
    "           \"CODMODALENV\":\"int\", \"CODPRIORPEDI\":\"int\", \"MTOVALUNIT\":\"double\", \"MTOSUBT\":\"double\", \"MTODSCTO\":\"double\", \"MTOBENEF\":\"double\", \"MTOVALVTA\":\"double\",\n",
    "           \"MTOIGV\":\"double\", \"MTOSUBTPROD\":\"double\", \"MTOCSTOENV\":\"double\", \"MTOTOTPROD\":\"double\", \"FECPEDID\":\"timestamp\", \"FECENV\":\"timestamp\",\n",
    "           \"FECCARGA\":\"timestamp\"},\n",
    "    date_col=\"FECCARGA\",\n",
    "    fillna_map={\"PEDIDO\":0, \"CTDPEDID\":0, \"CODMODVALVTA\":0, \"CODMEDIOPAGO\":0, \"FECCARGA\":\"1970-01-01 00:00:00\"},\n",
    "    non_negative_cols=[\"PEDIDO\"],\n",
    "    compute_metrics=True,        # <- calcula rows_in, duplicates_removed, etc.\n",
    "    output=\"both\"                # <- retorna (df, dq)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c20368-3c36-4f7b-bfaa-c7babef14f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG desarrollo;\n",
    "\n",
    "SHOW DATABASES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1464b6-cad3-42fe-bc79-967651597945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "def crear_tabla_delta_merge_managed(\n",
    "    nombre_df: str,\n",
    "    nombre_tabla: str,\n",
    "    llave_origen: List[str],\n",
    "    llave_destino: List[str],\n",
    "    db_name: str = \"default\",\n",
    "    catalog_name: str = \"desarrollo\",\n",
    "    partition_cols: Optional[List[str]] = None,\n",
    "    auto_merge_schema: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Crea si no existe una tabla Delta GESTIONADA en la base (que ya debe tener LOCATION en tu mount)\n",
    "    y realiza MERGE. No usa LOCATION expl√≠cito.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validaciones\n",
    "    df = globals()[nombre_df]\n",
    "\n",
    "    if len(llave_origen) != len(llave_destino):\n",
    "        print(\"‚ùå Error: La cantidad de columnas en 'llave_origen' y 'llave_destino' no coinciden.\")\n",
    "        return\n",
    "\n",
    "    if partition_cols:\n",
    "        faltantes = [c for c in partition_cols if c not in df.columns]\n",
    "        if faltantes:\n",
    "            print(f\"‚ùå Error: Columnas de partici√≥n no existen en el DataFrame: {faltantes}\")\n",
    "            return\n",
    "\n",
    "    if auto_merge_schema:\n",
    "        spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\", \"true\")\n",
    "\n",
    "    # Armar nombre completo\n",
    "    full_name = f\"{catalog_name}.{db_name}.{nombre_tabla}\"\n",
    "\n",
    "    # ‚úÖ FIX: usar el overload moderno (una sola cadena)\n",
    "    exists = spark.catalog.tableExists(full_name)\n",
    "\n",
    "    if not exists:\n",
    "        # Crear como TABLA GESTIONADA en el LOCATION de la DB (sin LOCATION expl√≠cito)\n",
    "        writer = df.write.format(\"delta\").mode(\"overwrite\")\n",
    "        if partition_cols:\n",
    "            # ‚úÖ FIX: varargs\n",
    "            writer = writer.partitionBy(*partition_cols)\n",
    "        writer.saveAsTable(full_name)\n",
    "        print(f\"‚úÖ Tabla gestionada creada: {full_name} (bajo LOCATION de la base '{db_name}')\")\n",
    "        return\n",
    "\n",
    "    # Si existe, MERGE\n",
    "    try:\n",
    "        delta_tbl = DeltaTable.forName(spark, full_name)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå La tabla {full_name} no es Delta o no es accesible como Delta: {e}\")\n",
    "\n",
    "    merge_condition = \" AND \".join(\n",
    "        [f\"tgt.`{llave_destino[i]}` = src.`{llave_origen[i]}`\" for i in range(len(llave_origen))]\n",
    "    )\n",
    "    set_expr  = {c: f\"src.`{c}`\" for c in df.columns}\n",
    "    vals_expr = {c: f\"src.`{c}`\" for c in df.columns}\n",
    "\n",
    "    print(f\"üîÑ Ejecutando MERGE INTO {full_name} ...\")\n",
    "    (delta_tbl.alias(\"tgt\")\n",
    "             .merge(df.alias(\"src\"), merge_condition)\n",
    "             .whenMatchedUpdate(set=set_expr)\n",
    "             .whenNotMatchedInsert(values=vals_expr)\n",
    "             .execute())\n",
    "    print(f\"‚úÖ MERGE completado para {full_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e0e5888-c56a-4bf8-b786-4c9b20faa5c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ejecutar la funci√≥n para crear la tabla y hacer MERGE usando diferentes llaves\n",
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Subcategoria\",\n",
    "    nombre_tabla=\"t_Subcategoria\",\n",
    "    llave_origen=[\"CODSUBCAT\"],\n",
    "    llave_destino=[\"CODSUBCAT\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3b34ff-9f14-42d4-a356-45db11f9dbc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Categoria\",\n",
    "    nombre_tabla=\"t_Categoria\",\n",
    "    llave_origen=[\"CODCAT\"],\n",
    "    llave_destino=[\"CODCAT\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8832808f-c9a7-457d-aabf-a066611aee41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Producto\",\n",
    "    nombre_tabla=\"t_Producto\",\n",
    "    llave_origen=[\"IDPRODUCTO\"],\n",
    "    llave_destino=[\"IDPRODUCTO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0425ba5-7b30-46f0-a5c6-a529f3503be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Moneda\",\n",
    "    nombre_tabla=\"t_Moneda\",\n",
    "    llave_origen=[\"CODMNDA\"],\n",
    "    llave_destino=[\"CODMNDA\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c2dc32f-4c47-45f2-a2d1-8456d1d0bb13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Ubigeo\",\n",
    "    nombre_tabla=\"t_Ubigeo\",\n",
    "    llave_origen=[\"CODUBIGEO\"],\n",
    "    llave_destino=[\"CODUBIGEO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d49c7f64-b366-43dd-bd58-52081e51bb01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Segmento\",\n",
    "    nombre_tabla=\"t_Segmento\",\n",
    "    llave_origen=[\"CODSGMNTO\"],\n",
    "    llave_destino=[\"CODSGMNTO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93639b82-500f-4132-b9ed-4624bed75e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Sectoreconomico\",\n",
    "    nombre_tabla=\"t_SectorEconomico\",\n",
    "    llave_origen=[\"CODSECTECON\"],\n",
    "    llave_destino=[\"CODSECTECON\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ddb7d6-3c07-4de7-b65f-3af5e4e57840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Mercado\",\n",
    "    nombre_tabla=\"t_Mercado\",\n",
    "    llave_origen=[\"CODMRCADO\"],\n",
    "    llave_destino=[\"CODMRCADO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d8d5ba-fb0c-47c5-84de-9a6a71f6c3b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# crear_tabla_delta_merge_managed(\n",
    "#     nombre_df=\"df_Cliente\",\n",
    "#     nombre_tabla=\"t_Cliente\",\n",
    "#     llave_origen=[\"IDCLI\"],\n",
    "#     llave_destino=[\"IDCLI\"],\n",
    "#     db_name=\"bronze_ventas\",\n",
    "#     partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbd6b919-4172-4f86-a648-c34edd162d28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Vendedor\",\n",
    "    nombre_tabla=\"t_Vendedor\",\n",
    "    llave_origen=[\"CODVEND\"],\n",
    "    llave_destino=[\"CODVEND\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f331e1f-33fe-4690-8bfd-a1d9e5631497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Prioridadpedido\",\n",
    "    nombre_tabla=\"t_Prioridadpedido\",\n",
    "    llave_origen=[\"CODPRIORPEDI\"],\n",
    "    llave_destino=[\"CODPRIORPEDI\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8fa1052-2c1b-4a4d-abaa-3bc58a91b5ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_ModalidadEnvio\",\n",
    "    nombre_tabla=\"t_ModalidadEnvio\",\n",
    "    llave_origen=[\"CODMODALENV\"],\n",
    "    llave_destino=[\"CODMODALENV\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7076775a-52b4-42da-b3b6-eb16de3e996f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Modalidadventa\",\n",
    "    nombre_tabla=\"t_Modalidadventa\",\n",
    "    llave_origen=[\"CODMODVALVTA\"],\n",
    "    llave_destino=[\"CODMODVALVTA\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d06427a-ecd0-41b4-af31-36e1d3125e00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Mediopago\",\n",
    "    nombre_tabla=\"t_mediopago\",\n",
    "    llave_origen=[\"CODMEDIOPAGO\"],\n",
    "    llave_destino=[\"CODMEDIOPAGO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "356d1210-9715-4c58-a194-0cfce98e634b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crear_tabla_delta_merge_managed(\n",
    "    nombre_df=\"df_Pedido\",\n",
    "    nombre_tabla=\"t_Pedido\",\n",
    "    llave_origen=[\"IDPEDIDO\"],\n",
    "    llave_destino=[\"IDPEDIDO\"],\n",
    "    db_name=\"bronze_ventas\",\n",
    "    partition_cols=[\"FECCARGA\"]  # opcional; si no quieres partici√≥n, qu√≠talo\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3522282755143179,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "uc_ventas01_extraccion_bronze_databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
